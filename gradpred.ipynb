{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "997d2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import deserialize, serialize\n",
    "from tensorflow.python.keras.saving import saving_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7e489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(model, training_config, weights):\n",
    "    restored_model = deserialize(model)\n",
    "    if training_config is not None:\n",
    "        restored_model.compile(\n",
    "            **saving_utils.compile_args_from_training_config(\n",
    "                training_config\n",
    "            )\n",
    "        )\n",
    "    restored_model.set_weights(weights)\n",
    "    return restored_model\n",
    "\n",
    "# Hotfix function\n",
    "def make_keras_picklable():\n",
    "\n",
    "    def __reduce__(self):\n",
    "        model_metadata = saving_utils.model_metadata(self)\n",
    "        training_config = model_metadata.get(\"training_config\", None)\n",
    "        model = serialize(self)\n",
    "        weights = self.get_weights()\n",
    "        return (unpack, (model, training_config, weights))\n",
    "\n",
    "    cls = Model\n",
    "    cls.__reduce__ = __reduce__\n",
    "\n",
    "# Run the function\n",
    "make_keras_picklable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d4d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a092acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Downloads/Admission_Predict_Ver1.1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c217d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Serial No.'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76bd1151",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5afa982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef5e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31a1d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7,activation = 'relu',input_dim = 7))\n",
    "model.add(Dense(7,activation = 'relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dc85c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error',optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88f36b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3269 - val_loss: 0.3083\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2433 - val_loss: 0.2349\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1952 - val_loss: 0.1962\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1704 - val_loss: 0.1745\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1548 - val_loss: 0.1563\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1382 - val_loss: 0.1386\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1198\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1056 - val_loss: 0.0994\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0880 - val_loss: 0.0786\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 878us/step - loss: 0.0693 - val_loss: 0.0566\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.0380\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.0264\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0210\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0191\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0180\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0170\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0159\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 864us/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0133\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0127\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0122\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 960us/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0093\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0091\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0090\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0088\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0085\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0084\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0082\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 906us/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0066\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0064\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 995us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 992us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 896us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 994us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f4dd035580>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled,y_train,epochs = 100,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccb42dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gradpred.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04b0b228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64887375],\n",
       "       [0.65486324],\n",
       "       [1.0029998 ],\n",
       "       [0.68328404],\n",
       "       [0.8085306 ],\n",
       "       [0.65291125],\n",
       "       [0.74210113],\n",
       "       [0.75404704],\n",
       "       [0.7557533 ],\n",
       "       [0.6477046 ],\n",
       "       [0.6893057 ],\n",
       "       [0.68884724],\n",
       "       [0.8431833 ],\n",
       "       [0.8234815 ],\n",
       "       [0.7444262 ],\n",
       "       [0.85462695],\n",
       "       [0.6197678 ],\n",
       "       [0.73470026],\n",
       "       [0.8937357 ],\n",
       "       [0.69379014],\n",
       "       [0.59956497],\n",
       "       [0.72500265],\n",
       "       [0.84325534],\n",
       "       [0.7631077 ],\n",
       "       [0.8290473 ],\n",
       "       [0.61025816],\n",
       "       [0.94676965],\n",
       "       [0.63940614],\n",
       "       [0.82368344],\n",
       "       [0.65277725],\n",
       "       [0.6326701 ],\n",
       "       [0.7799405 ],\n",
       "       [0.5841362 ],\n",
       "       [0.8919296 ],\n",
       "       [0.57257366],\n",
       "       [0.79172856],\n",
       "       [0.7237785 ],\n",
       "       [0.6524678 ],\n",
       "       [0.66932786],\n",
       "       [0.90260655],\n",
       "       [0.5469816 ],\n",
       "       [0.643248  ],\n",
       "       [0.82051206],\n",
       "       [0.9469512 ],\n",
       "       [0.76313615],\n",
       "       [0.49272537],\n",
       "       [0.68941146],\n",
       "       [0.6518629 ],\n",
       "       [0.756277  ],\n",
       "       [0.6584847 ],\n",
       "       [0.8360706 ],\n",
       "       [0.89946973],\n",
       "       [0.9009577 ],\n",
       "       [0.6253546 ],\n",
       "       [0.77109295],\n",
       "       [0.568886  ],\n",
       "       [0.7146525 ],\n",
       "       [0.59901947],\n",
       "       [0.6918597 ],\n",
       "       [0.6905966 ],\n",
       "       [0.43525928],\n",
       "       [0.7584969 ],\n",
       "       [0.7885776 ],\n",
       "       [0.8557102 ],\n",
       "       [0.97179306],\n",
       "       [0.60435927],\n",
       "       [0.7188502 ],\n",
       "       [0.819441  ],\n",
       "       [0.96641237],\n",
       "       [0.7241757 ],\n",
       "       [0.5848233 ],\n",
       "       [0.67977965],\n",
       "       [0.793512  ],\n",
       "       [0.5408592 ],\n",
       "       [0.9426927 ],\n",
       "       [0.5804766 ],\n",
       "       [0.90256137],\n",
       "       [0.8981753 ],\n",
       "       [0.70634025],\n",
       "       [0.7231799 ],\n",
       "       [0.8926051 ],\n",
       "       [0.47959977],\n",
       "       [0.9315719 ],\n",
       "       [0.81368315],\n",
       "       [0.835721  ],\n",
       "       [0.677069  ],\n",
       "       [0.8570801 ],\n",
       "       [0.88862175],\n",
       "       [0.5618109 ],\n",
       "       [0.5885321 ],\n",
       "       [0.63658106],\n",
       "       [0.7744468 ],\n",
       "       [0.6265413 ],\n",
       "       [0.7107317 ],\n",
       "       [0.7699451 ],\n",
       "       [0.83261895],\n",
       "       [0.8267201 ],\n",
       "       [0.5285099 ],\n",
       "       [0.7319314 ],\n",
       "       [0.68217725]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_model = pickle.load(open('gradpred.pkl', 'rb'))\n",
    "pickled_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "261f33df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.46      ,  0.5       ,  0.25      ,  0.375     ,  0.14285714,\n",
       "         0.5224359 ,  0.        ],\n",
       "       [ 0.44      ,  0.53571429,  0.5       ,  0.5       ,  0.42857143,\n",
       "         0.53205128,  1.        ],\n",
       "       [ 0.98      ,  0.96428571,  1.        ,  0.875     ,  0.71428571,\n",
       "         0.92948718,  0.        ],\n",
       "       [ 0.52      ,  0.53571429,  0.25      ,  0.625     ,  0.57142857,\n",
       "         0.58974359,  1.        ],\n",
       "       [ 0.7       ,  0.64285714,  0.75      ,  0.875     ,  0.71428571,\n",
       "         0.69230769,  1.        ],\n",
       "       [ 0.42      ,  0.32142857,  0.25      ,  0.375     ,  0.57142857,\n",
       "         0.49358974,  1.        ],\n",
       "       [ 0.6       ,  0.42857143,  0.5       ,  0.5       ,  0.57142857,\n",
       "         0.62179487,  1.        ],\n",
       "       [ 0.74      ,  0.39285714,  0.5       ,  0.75      ,  0.71428571,\n",
       "         0.48076923,  1.        ],\n",
       "       [ 0.62      ,  0.67857143,  0.5       ,  0.625     ,  0.71428571,\n",
       "         0.65064103,  1.        ],\n",
       "       [ 0.56      ,  0.5       ,  0.25      ,  0.75      ,  0.71428571,\n",
       "         0.35897436,  1.        ],\n",
       "       [ 0.48      ,  0.53571429,  0.25      ,  0.375     ,  0.71428571,\n",
       "         0.47115385,  0.        ],\n",
       "       [ 0.06      ,  0.17857143,  0.25      ,  0.25      ,  0.71428571,\n",
       "         0.32051282,  1.        ],\n",
       "       [ 0.74      ,  0.42857143,  1.        ,  0.5       ,  0.57142857,\n",
       "         0.65384615,  1.        ],\n",
       "       [ 0.74      ,  0.78571429,  0.5       ,  0.5       ,  0.42857143,\n",
       "         0.71153846,  0.        ],\n",
       "       [ 0.62      ,  0.60714286,  0.5       ,  0.625     ,  0.57142857,\n",
       "         0.64102564,  1.        ],\n",
       "       [ 0.68      ,  0.71428571,  1.        ,  1.        ,  1.        ,\n",
       "         0.73076923,  1.        ],\n",
       "       [ 0.32      ,  0.39285714,  0.5       ,  0.625     ,  0.42857143,\n",
       "         0.45192308,  0.        ],\n",
       "       [ 0.46      ,  0.60714286,  0.5       ,  0.75      ,  0.57142857,\n",
       "         0.70512821,  0.        ],\n",
       "       [ 0.82      ,  0.82142857,  1.        ,  0.75      ,  0.57142857,\n",
       "         0.84615385,  1.        ],\n",
       "       [ 0.5       ,  0.46428571,  0.5       ,  0.25      ,  0.28571429,\n",
       "         0.53846154,  0.        ],\n",
       "       [ 0.44      ,  0.21428571,  0.        ,  0.625     ,  0.42857143,\n",
       "         0.44230769,  1.        ],\n",
       "       [ 0.42      ,  0.53571429,  0.75      ,  0.875     ,  0.85714286,\n",
       "         0.70512821,  1.        ],\n",
       "       [ 0.76      ,  0.57142857,  0.75      ,  0.875     ,  0.71428571,\n",
       "         0.76282051,  1.        ],\n",
       "       [ 0.16      ,  0.32142857,  0.75      ,  0.375     ,  0.85714286,\n",
       "         0.28525641,  1.        ],\n",
       "       [ 0.7       ,  0.71428571,  0.75      ,  0.625     ,  0.57142857,\n",
       "         0.67948718,  0.        ],\n",
       "       [ 0.5       ,  0.46428571,  0.25      ,  0.25      ,  0.28571429,\n",
       "         0.2724359 ,  0.        ],\n",
       "       [ 0.82      ,  0.71428571,  1.        ,  0.75      ,  1.        ,\n",
       "         0.96153846,  1.        ],\n",
       "       [ 0.36      ,  0.5       ,  0.5       ,  0.5       ,  0.42857143,\n",
       "         0.46153846,  0.        ],\n",
       "       [ 0.66      ,  0.75      ,  0.75      ,  0.75      ,  0.85714286,\n",
       "         0.77884615,  1.        ],\n",
       "       [ 0.5       ,  0.64285714,  0.25      ,  0.625     ,  0.42857143,\n",
       "         0.53205128,  1.        ],\n",
       "       [ 0.34      ,  0.35714286,  0.5       ,  0.5       ,  0.42857143,\n",
       "         0.47115385,  0.        ],\n",
       "       [ 0.66      ,  0.64285714,  0.5       ,  0.75      ,  0.57142857,\n",
       "         0.73717949,  1.        ],\n",
       "       [ 0.28      ,  0.28571429,  0.25      ,  0.375     ,  0.57142857,\n",
       "         0.40705128,  0.        ],\n",
       "       [ 0.82      ,  0.85714286,  0.75      ,  0.875     ,  0.85714286,\n",
       "         0.84615385,  1.        ],\n",
       "       [ 0.52      ,  0.21428571,  0.        ,  0.125     ,  0.14285714,\n",
       "         0.20192308,  0.        ],\n",
       "       [ 0.72      ,  0.71428571,  0.5       ,  0.625     ,  0.42857143,\n",
       "         0.73717949,  1.        ],\n",
       "       [ 0.6       ,  0.32142857,  0.25      ,  0.375     ,  0.42857143,\n",
       "         0.58333333,  0.        ],\n",
       "       [ 0.48      ,  0.39285714,  0.25      ,  0.25      ,  0.42857143,\n",
       "         0.45192308,  0.        ],\n",
       "       [ 0.5       ,  0.46428571,  0.25      ,  0.5       ,  0.42857143,\n",
       "         0.49358974,  0.        ],\n",
       "       [ 0.88      ,  0.85714286,  0.75      ,  0.75      ,  0.57142857,\n",
       "         0.87820513,  1.        ],\n",
       "       [ 0.18      ,  0.28571429,  0.5       ,  0.25      ,  0.14285714,\n",
       "         0.39102564,  0.        ],\n",
       "       [ 0.42      ,  0.42857143,  0.5       ,  0.75      ,  0.57142857,\n",
       "         0.42628205,  1.        ],\n",
       "       [ 0.56      ,  0.32142857,  1.        ,  0.625     ,  1.        ,\n",
       "         0.63461538,  1.        ],\n",
       "       [ 0.86      ,  0.96428571,  1.        ,  1.        ,  0.85714286,\n",
       "         0.95512821,  1.        ],\n",
       "       [ 0.74      ,  0.75      ,  0.5       ,  0.625     ,  0.42857143,\n",
       "         0.59615385,  1.        ],\n",
       "       [ 0.14      ,  0.14285714,  0.25      ,  0.375     ,  0.        ,\n",
       "         0.34935897,  0.        ],\n",
       "       [ 0.54      ,  0.28571429,  0.25      ,  0.5       ,  0.28571429,\n",
       "         0.56730769,  0.        ],\n",
       "       [ 0.5       ,  0.42857143,  0.5       ,  0.75      ,  0.28571429,\n",
       "         0.41666667,  0.        ],\n",
       "       [ 0.64      ,  0.39285714,  0.75      ,  0.5       ,  0.28571429,\n",
       "         0.39102564,  1.        ],\n",
       "       [ 0.48      ,  0.5       ,  0.25      ,  0.75      ,  0.57142857,\n",
       "         0.46474359,  0.        ],\n",
       "       [ 0.78      ,  0.67857143,  0.75      ,  0.875     ,  0.71428571,\n",
       "         0.70833333,  1.        ],\n",
       "       [ 0.82      ,  0.89285714,  0.75      ,  0.875     ,  1.        ,\n",
       "         0.83974359,  1.        ],\n",
       "       [ 0.8       ,  0.82142857,  1.        ,  0.875     ,  0.42857143,\n",
       "         0.81410256,  1.        ],\n",
       "       [ 0.36      ,  0.35714286,  0.25      ,  0.25      ,  0.57142857,\n",
       "         0.37820513,  1.        ],\n",
       "       [ 0.5       ,  0.32142857,  0.5       ,  0.625     ,  0.85714286,\n",
       "         0.74679487,  0.        ],\n",
       "       [ 0.28      ,  0.46428571,  0.25      ,  0.5       ,  0.42857143,\n",
       "         0.44871795,  1.        ],\n",
       "       [ 0.44      ,  0.53571429,  0.75      ,  0.875     ,  0.71428571,\n",
       "         0.59294872,  1.        ],\n",
       "       [ 0.38      ,  0.5       ,  0.25      ,  0.375     ,  0.28571429,\n",
       "         0.38461538,  0.        ],\n",
       "       [ 0.58      ,  0.5       ,  0.5       ,  0.75      ,  0.42857143,\n",
       "         0.38461538,  1.        ],\n",
       "       [ 0.56      ,  0.53571429,  0.5       ,  0.5       ,  0.57142857,\n",
       "         0.47115385,  1.        ],\n",
       "       [ 0.18      ,  0.07142857,  0.        ,  0.        , -0.14285714,\n",
       "         0.17307692,  0.        ],\n",
       "       [ 0.58      ,  0.39285714,  0.75      ,  0.875     ,  0.57142857,\n",
       "         0.59615385,  0.        ],\n",
       "       [ 0.68      ,  0.28571429,  0.5       ,  0.75      ,  1.        ,\n",
       "         0.58974359,  1.        ],\n",
       "       [ 0.8       ,  0.78571429,  0.75      ,  0.875     ,  0.42857143,\n",
       "         0.75961538,  1.        ],\n",
       "       [ 0.9       ,  0.89285714,  1.        ,  1.        ,  1.        ,\n",
       "         0.96794872,  1.        ],\n",
       "       [ 0.36      ,  0.42857143,  0.25      ,  0.375     ,  0.42857143,\n",
       "         0.40705128,  0.        ],\n",
       "       [ 0.6       ,  0.57142857,  0.5       ,  0.625     ,  0.71428571,\n",
       "         0.52564103,  1.        ],\n",
       "       [ 0.68      ,  0.53571429,  1.        ,  0.625     ,  0.71428571,\n",
       "         0.59615385,  1.        ],\n",
       "       [ 1.        ,  0.71428571,  0.75      ,  1.        ,  0.85714286,\n",
       "         0.91666667,  1.        ],\n",
       "       [ 0.56      ,  0.60714286,  0.5       ,  0.5       ,  0.42857143,\n",
       "         0.54487179,  0.        ],\n",
       "       [ 0.3       ,  0.35714286,  0.25      ,  0.25      ,  0.28571429,\n",
       "         0.44230769,  0.        ],\n",
       "       [ 0.5       ,  0.42857143,  0.5       ,  0.5       ,  0.28571429,\n",
       "         0.49038462,  0.        ],\n",
       "       [ 0.72      ,  0.78571429,  0.5       ,  0.5       ,  0.42857143,\n",
       "         0.74038462,  1.        ],\n",
       "       [ 0.4       ,  0.25      ,  0.25      ,  0.125     ,  0.14285714,\n",
       "         0.16025641,  0.        ],\n",
       "       [ 0.96      ,  0.89285714,  0.75      ,  0.625     ,  0.85714286,\n",
       "         0.8525641 ,  1.        ],\n",
       "       [ 0.28      ,  0.53571429,  0.5       ,  0.625     ,  0.42857143,\n",
       "         0.33974359,  0.        ],\n",
       "       [ 0.84      ,  0.57142857,  1.        ,  0.875     ,  0.71428571,\n",
       "         0.71153846,  1.        ],\n",
       "       [ 0.66      ,  0.67857143,  1.        ,  0.75      ,  1.        ,\n",
       "         0.98076923,  1.        ],\n",
       "       [ 0.6       ,  0.42857143,  0.5       ,  0.5       ,  0.28571429,\n",
       "         0.56730769,  1.        ],\n",
       "       [ 0.48      ,  0.60714286,  0.75      ,  0.625     ,  0.71428571,\n",
       "         0.63141026,  1.        ],\n",
       "       [ 0.74      ,  0.57142857,  1.        ,  1.        ,  0.57142857,\n",
       "         0.74679487,  1.        ],\n",
       "       [ 0.        ,  0.42857143,  0.75      ,  0.25      ,  0.28571429,\n",
       "         0.21153846,  0.        ],\n",
       "       [ 0.9       ,  0.92857143,  1.        ,  0.875     ,  0.57142857,\n",
       "         0.84615385,  1.        ],\n",
       "       [ 0.74      ,  0.5       ,  0.75      ,  0.75      ,  0.85714286,\n",
       "         0.625     ,  1.        ],\n",
       "       [ 0.64      ,  0.64285714,  1.        ,  0.875     ,  0.71428571,\n",
       "         0.69551282,  0.        ],\n",
       "       [ 0.36      ,  0.60714286,  0.25      ,  0.5       ,  0.71428571,\n",
       "         0.52884615,  0.        ],\n",
       "       [ 0.68      ,  0.75      ,  1.        ,  0.75      ,  1.        ,\n",
       "         0.78525641,  1.        ],\n",
       "       [ 0.82      ,  0.85714286,  1.        ,  0.75      ,  0.71428571,\n",
       "         0.78846154,  1.        ],\n",
       "       [ 0.14      ,  0.25      ,  0.75      ,  0.5       ,  0.57142857,\n",
       "         0.32371795,  0.        ],\n",
       "       [ 0.28      ,  0.42857143,  0.5       ,  0.375     ,  0.14285714,\n",
       "         0.42307692,  0.        ],\n",
       "       [ 0.38      ,  0.46428571,  0.75      ,  0.625     ,  0.14285714,\n",
       "         0.44230769,  0.        ],\n",
       "       [ 0.62      ,  0.35714286,  0.5       ,  0.625     ,  0.71428571,\n",
       "         0.70833333,  1.        ],\n",
       "       [ 0.52      ,  0.39285714,  0.5       ,  0.625     ,  0.14285714,\n",
       "         0.28205128,  0.        ],\n",
       "       [ 0.62      ,  0.60714286,  0.5       ,  0.5       ,  0.71428571,\n",
       "         0.44871795,  1.        ],\n",
       "       [ 0.64      ,  0.71428571,  0.75      ,  0.625     ,  0.28571429,\n",
       "         0.71153846,  1.        ],\n",
       "       [ 0.74      ,  0.67857143,  0.75      ,  0.75      ,  0.85714286,\n",
       "         0.70512821,  1.        ],\n",
       "       [ 0.64      ,  0.78571429,  1.        ,  0.875     ,  0.71428571,\n",
       "         0.68589744,  1.        ],\n",
       "       [ 0.16      ,  0.21428571,  0.25      ,  0.75      ,  0.42857143,\n",
       "         0.39423077,  0.        ],\n",
       "       [ 0.52      ,  0.64285714,  0.5       ,  0.625     ,  0.71428571,\n",
       "         0.56410256,  0.        ],\n",
       "       [ 0.3       ,  0.57142857,  1.        ,  0.5       ,  0.42857143,\n",
       "         0.53846154,  0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8eda46e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81218106]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = [[320,100,3,4,4,9.36,0]]\n",
    "obs_scaled = scaler.transform(obs)\n",
    "\n",
    "pickled_model.predict(obs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da5951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
